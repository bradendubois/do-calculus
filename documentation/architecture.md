# Architecture

An outline of the design and architecture of the software.

#### Main

This is the file to be run directly. Its order of operations are as follows:

- If enabled, a shell script is run which will run a ``git pull``; this will (hopefully) allow the software to update without a restart.
- If enabled, the regression suite first runs. Results are returned to Main, which may be output.
- After this, the graph file location specified is read, and listed. The user selects a file, which is loaded into the REPL Driver.
- The user can interact with the main REPL Driver until exiting, after which they are prompted to select another file or exit.

Below is each subdirectory of the project, with a description of its purpose and each file within it.

## Causal Graphs

This is the default subdirectory containing each Causal Graph file, which can be loaded by the software.

For more information on Causal Graph files, see ``documentation/Causal Graph Files``.

## Config

This subdirectory controls all configuration file settings, from creating a configuration file to accessing them, repairing the user's file, etc.

- ``config.json``: Generated on running the software for the first time: a basic JSON file of all settings.
- ``config_manager.py``: Can be directly run, and is imported into the software; an ``access`` method is provided as a way of abstracting accessing specific settings. This option allows the software to detect invalid or missing settings and revert it to a pre-defined "default".
- ``primary_configuration.py``: A primary/source file that defines all settings for the project: it's broken into sections, with every parameter having its settings name, a documentation name, a default value, a set of options, etc.
- ``generate_config_docs.py``: By using the ``primary_configuration.py``, a Markdown file is generated and placed in ``documentation``; all the settings and details are outlined in this file, named ``Configuration``.

## Debug

This subdirectory is a collection of scripts and text files used for various debugging / development purposes. It's the scrap paper of development, and anything in here is not likely to work. It's mostly used to test something or flesh out an idea.

**Nothing** in the "main" software will ever use or rely on anything located in ``debug``. As well, a "build" may not even have this directory present.

## Documentation

This subdirectory contains all the documentation for the project (with the exception of the README and Quick Usage in the root of the project).

The subdirectory ``readme_sections`` contains 3 files, README_1, README_2, README_3. These files are "stitched together" to create the README placed in the root of the project.

- ``README_1``: An introduction / requirements list for running the project.
- ``README_2``: A "Quick Usage", which is actually turned into the Quick Usage at the root of the project.
- ``README_3``: A "details" section which outlines all the files in ``documentation`` to seek for further information.

Quick Usage is actually the middle section of README; this is simply done for, aptly-named, Quick Usage.

**Note**: ``readme_sections`` may not be present in a "build", though the compiled Quick Usage / README will be.

- ``Architecture``: This file! Outlining the purpose/layout of each component of the project.
- ``Causal Graph Files``: Outlines the layout and creation of Causal Graph files, for use in the project.
- ``Configuration``: The documentation on configuration files, as generated by ``config/generate_config_docs.py``.
- ``Decorator Usage``: Not incredibly relevant, but Python decorators are implemented to allow functions to be timed/debugged. A short explanation of how they are used.
- ``Regression Tests``: Outlines how the regression suite works and how to create test files.

## Logs

This subdirectory is the default location for computations / regression tests to be logged to.

- ``regression`` is the default subdirectory to which regression tests will be entirely written. A "lock" is placed on the IO logging module so that the entire regression suite will be logged to one file, which is named after the date/time the suite is started.

## Probability Structures


########################################################################################################################



This is a small class that represents a Variable. It requires a unique *name*, and some list of possible *outcomes*. For example, a variable X may have outcomes x, ~x.

Located in ``probability_structures/VariableStructures``.

### Outcomes

This is a class representing a specific outcome of a variable. For example, one outcome of X may be x, and we can create an Outcome object to represent that the Variable is X, and the *outcome* is x.

Located in ``probability_structures/VariableStructures``.

### Interventions

This is a class representing an "intervention" / do(X). It is functionally equivalent to the Outcome class, except for purposes of do-calculus, we want to identify that this is a *special kind of outcome*.

Located in ``probability_structures/VariableStructures``.

### Conditional Probability Tables

This represents a specific table for a variable and its parents.

The ``__str__`` method is fairly dense, but the idea is to pack all the information into a numpy table for easier formatting (easily accessing columns, etc.), and then we can do things like padding by measuring the widest item in a column, and adding appropriate spacing to all the other boxes in this column, etc.

The ``probability_lookup`` is the most important; we want to go through, row by row on the table, and if this specific row's set of outcomes matches our given set, we can return this row's probability.

### Backdoor Controller

For the Backdoor Controller, most of it is fairly straightforward; the key to the backdoor detection algorithm is understanding the meaning of a backdoor path, and especially so on "blocking" these paths. You find that a variable might be necessarily in Z, but in putting it in Z (as in the case of a collider) can still *open* a path; the path-finding must be nuanced enough to understand that something in Z or not in Z changes whether we can go "up" (child to parent), "down" (parent to child), or both.

Generally, however, we want to find all sufficient sets Z. We begin by taking all variables in G, and removing any that could not possibly be in Z. This is easy enough; we cannot have a variable in X or Y in Z. We can not have a variable along a straight-forward path from X to Y in Z either; the use of an incredibly helpful path algorithm provided by Dr. Neufeld is employed here. We take the remaining variables (after removing X, Y, and all variables along X->Y) and take the power set; any possible set in this may be a sufficient Z if it blocks all back-door paths.

The backdoor detection algorithm for backdoor paths from X -> Y, with a de-confounder Z take the cross product of X and Y, and sees if a backdoor path exists along any of these. The actual path-finding is as a follows (starting from x, searching for y):

```pseudo
backdoor(x, y, Z, current path, paths, previous movement)
    
    if x == y
        we complete a backdoor path
        return all paths so far, plus this path

    if x is not in the path

        if previous movement was down

            if x is in Z, or a descendant of x is in Z
                for every parent of x
                    paths = backdoor(parent, y, current path + x, paths, up)


            if x is not in Z
                for every child of x
                    paths = backdoor(child, y, current path + x, paths, down)

        if previous movement was up
            if x is not in Z
                
                for every parent of x
                    paths = backdoor(parent, y, current path + x, paths, up)
                for every child of x
                    paths = backdoor(child, y, current path + x, paths, up)

    return paths 
```

The idea is that we can always move "up" or "down" through non-controlled variables if we are heading in the same direction. This is consistent with Pearl's definitions, where a path can be blocked along i -> j -> k, if j is in Z. We can also move up, then down, if the variable is not in Z, just as i <- j -> k, where j is *not* in Z. We can also move down, then up, if this variable is in Z, or a child of Z is; i -> j <- k, where j is in Z.

### Causal Graphs

TODO - The Causal Graph is the undoubtedly the largest part of the software, driving standard probability computations (relying on the Backdoor Controller when do-calculus is deployed).



########################################################################################################################

## Scripts

This subdirectory contains a few shell scripts.

- ``build_readme.sh``: This is used to generate all documentation for the project, in which different Markdown files are (sometimes concatenated) and compiled to PDF, using pandoc.
- ``git_update.sh``: Very small; just does a "git pull" and sets some configurations so that Github will save the username/password so that future pulls will not need to login.
- ``prepare_build.sh``: Generates a "production build" of sorts; uploading the development directory as-is typically results in exceptionally large wait times, as subdirectories such as ``.git`` or ``.idea`` contain hundreds of small files. This will create a version-labelled subdirectory, copying all the Python code, causal graphs, regression suite, etc. All Markdown documentation will be compiled into PDF form. No logs will be copied, nor will the entire ``debug`` subdirectory``. This final build produced is ideal for sharing/sending to someone else to use if they will not be changing the code.

## Tests

This subdirectory contains the default location for test files, as well as a subdirectory for test-specific graph files.

For more information on how to create and add tests, see ``Regression Tests``.

- ``test_files``: The default subdirectory containing all the test files for the regression suite to run.
- ``test_graphs``: The default subdirectory to place a test-specific graph, which are not to be shown/loaded by the software.

## Util

A large collection of utilities / modules that are re-used throughout the project and as such, can be isolated from the main probability code module.

- ``decorators.py``: A couple of decorators (see ``Decorators``) that allow debugging and timing of functions.
- ``IO_Logger.py``: A main IO module that allows minimal coding to relay information to both the terminal output as well as being simultaneously written to a text file. Methods exist to open a file to write to, close any open file, lock the file stream to prevent switching files. Optional ``x_offset`` parameter in writing allows a multi-line message to be horizontally shifted to signal recursive depth; especially useful in probability queries.
- ``ProbabilityExceptions.py``: A collection of custom Exceptions to be raised when input is invalid, queries cannot be computed, etc. and caught, but are separate from standard AssertionErrors, NoneTypeErrors, etc. and are handled separately.
- ``RegressionTesting.py``: The main driver of the regression test suite (see ``Regression Tests``), in which each test file (by default, located in ``tests/test_files``) is loaded and run. Results across each file are stored and returned as a list of results, so that each test file can be viewed separately.
- ``ResultCache.py``: A simple abstraction of a dictionary, in which any string representation of a query can be stored with a value that is computed, so that it can be later looked up rather than recomputed. This can be enabled/disabled by the configuration file. **Note**: The dictionary is cleared on any file being loaded, as a variable in one file with the same name as a different variable will likely have cached different values.

The subdirectory ``helpers`` consists of a few very small "helpers", where their isolated code allows the "main" code to be far more readable.

- ``CallableItemWrapper.py``: A small menu system is created in ``parsers/UserIndexSelection``, and in generating/spacing in the menu, if the first component of an entry is "callable" (callable(print) -> True, callable(1) -> False), this component will not be shown. It provides a workaround to take a list of lists of data and strings, and still generate a menu.
- ``DisjointSets.py``: A tiny helper that takes an arbitrary number of sets and returns whether they are all completely disjoint.
- ``MinimizeSets.py``: Takes a set of sets and sorts them by size and returns a list of minimal sets to sufficiently represent the input sets. Used in the Backdoor Controller if the option to only show minimal sufficient Z sets is enabled.
- ``PowerSet.py``: Takes an iterable and returns a chain representing the iterable's power set. Optional flag to control whether to consider the empty set.

The subdirectory ``parsers`` contains modules used in parsing/reading input from the user for various purposes.

- ``GetHeadAndBody.py``: Used to abstract the process of asking the user for valid input on getting a valid head and body used in probability queries, such as P(Y=y | X=~x, Z=z).
- ``GraphLoader.py``: Used to complete load, read, and parse the contents of a Graph File (see ``Causal Graph Files``).
- ``ProbabilityString.py``: Used to take a head and body of a query, and convert it to a string representation, like "P(Y=y | do(X=x), Z=z)".
- ``UserIndexSelection.py``: Used to take a list, or list of lists, of data, and generate a well-formatted menu to the user and get an integer selection as to which index of the data they want to select.
